"""
A small backend to querry the models
"""

import sys
import pickle
import numpy as np
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline
from tensorflow import keras
from keras.models import load_model
from keras.preprocessing.sequence import pad_sequences
from pydantic import BaseModel

sys.path.append("./utils")
from utils import preprocess_text, tokenise

app = FastAPI()

# Allow all origins (for development purposes)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

generative_tokenizer = GPT2Tokenizer.from_pretrained(
    "saved_models/generative_tokenizer"
)
generative_model = GPT2LMHeadModel.from_pretrained("saved_models/generative_model")
generator = pipeline(
    "text-generation", model=generative_model, tokenizer=generative_tokenizer
)

classification_model = load_model("saved_models/classification_model.keras")
with open("saved_models/classification_tokenizer.pickle", "rb") as handle:
    classification_tokenizer = pickle.load(handle)

parties = ["extreme gauche", "gauche", "centre", "droite", "extreme droite"]


class SpeechRequest(BaseModel):
    """
    Classification request body format
    """

    speech: str


@app.post("/classify/")
def classify_speech(speech_request: SpeechRequest):
    """
    Classify a speech to a political party
    """
    speech = preprocess_text(speech_request.speech)
    speech = tokenise(speech)

    processed_speech = classification_tokenizer.texts_to_sequences([speech])
    processed_speech = np.array(
        pad_sequences(processed_speech, padding="post", maxlen=5000)
    )

    return {
        "party": parties[
            np.argmax(classification_model.predict(processed_speech), axis=1)[0]
        ]
    }


@app.get("/generate/{party}")
def generate_speech(party: str):
    """
    Returns a speech generated by the model for the specified party
    """
    prompt = f"<|party|>{party}\n<|speech|>"
    result = generator(
        prompt,
        max_new_tokens=1024,
        num_return_sequences=1,
        do_sample=True,
        temperature=0.75,
    )
    return {
        "speech": result[0]["generated_text"]
        .replace(f"<|party|>{party}\n<|speech|>", "")
        .rsplit(".", 1)[0]
        + "."
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
