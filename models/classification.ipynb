{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1c5e9c",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this file, we train an LSTM to be able to classify a speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../data\")\n",
    "from load_data import load_data\n",
    "\n",
    "SAVE_PATH = \"../saved_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09427585",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(data[\"text\"])\n",
    "flattened_documents = [\" \".join(doc) for doc in documents]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(flattened_documents)\n",
    "\n",
    "with open(f\"{SAVE_PATH}/classification_tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c822648",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(flattened_documents)\n",
    "maxlen = 5000\n",
    "X = np.array(pad_sequences(X, padding=\"post\", maxlen=maxlen))\n",
    "y = np.array(to_categorical(list(data[\"speaker\"]), num_classes=5))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21534490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=250, input_shape=(maxlen,)))\n",
    "model.add(Bidirectional(LSTM(units=150)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=128, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(units=5, activation=\"softmax\", kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001, clipvalue=1.0), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "model.save(f\"{SAVE_PATH}/classification_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
